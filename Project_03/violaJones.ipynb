{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=blue> Load datasets (train and test) and save in a pickle file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "faceDir_train     = './dataset/train/face/*.pgm'\n",
    "nonfaceDir_train  = './dataset/train/non-face/*.pgm'\n",
    "\n",
    "# 0 --> grayscale \n",
    "face_images       = [(cv2.imread(file,0),1) for file in glob.glob(faceDir_train)]\n",
    "nonface_images    = [(cv2.imread(file,0),0) for file in glob.glob(nonfaceDir_train)]\n",
    "\n",
    "face_count    = len(face_images)\n",
    "nonface_count = len(nonface_images)\n",
    "\n",
    "train_ds = face_images + nonface_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total face image: 2429\n",
      "Total non-face image: 4548\n",
      "Total image: 6977\n"
     ]
    }
   ],
   "source": [
    "print(\"Total face image: \" + str(face_count))\n",
    "print(\"Total non-face image: \" + str(nonface_count))\n",
    "print(\"Total image: \" + str(len(train_ds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving in a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_ds.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_ds,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading a pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6977\n"
     ]
    }
   ],
   "source": [
    " with open(\"train_ds.pkl\", 'rb') as f:\n",
    "        t = pickle.load(f)\n",
    "        print(len(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=#9933FF> Integral Image Calculation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcIntegral(img):\n",
    "    \"\"\"\n",
    "    This method returns the integral image of a given image\n",
    "           ------ \n",
    "          | Args:|\n",
    "           ------\n",
    "    img: A 2d-numpy array of original image\n",
    "    \n",
    "    \"\"\"\n",
    "    rows = img.shape[0]\n",
    "    cols = img.shape[1]\n",
    "    \n",
    "    new_img = np.zeros((rows,cols))\n",
    "    \n",
    "    new_img[0][0] = img[0][0]\n",
    "    \n",
    "    '''\n",
    "        1st row calculation\n",
    "    '''\n",
    "    for c in range(1,cols):\n",
    "        new_img[0][c] = new_img[0][c-1] + img[0][c]\n",
    "   \n",
    "    '''\n",
    "        1st column calculation\n",
    "    '''\n",
    "    for r in range(1,rows):\n",
    "        new_img[r][0] = new_img[r-1][0] + img[r][0] \n",
    "    \n",
    "    '''\n",
    "        Other cell calculation\n",
    "    '''\n",
    "    for r in range(1,rows):\n",
    "        for c in range(1,cols):\n",
    "            new_img[c][r] = (new_img[c-1][r]+new_img[c][r-1]-new_img[c-1][r-1]) + (img[c][r])\n",
    "    \n",
    "    return new_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  <font color=red>Rectangle Class </font> - A helper class for `Haar Feature` calculation. \n",
    "### <font color=blue> A Haar Feature is a collection of Rectangle Regions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rectangle:\n",
    "    # constructor\n",
    "    def __init__(self, x, y, width, height):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "    \n",
    "    # Return the sum of all pixels inside a rectangle for a specific integral image\n",
    "    def compute_sum(self, integralImg):\n",
    "        \n",
    "        x = self.x\n",
    "        y = self.y\n",
    "        width  = self.width\n",
    "        height = self.height\n",
    "     \n",
    "        one   = integralImg[y][x]\n",
    "        two   = integralImg[y][x+width]\n",
    "        three = integralImg[y+height][x]\n",
    "        four  = integralImg[y+height][x+width]\n",
    "        \n",
    "        desiredSum = (one + four) - (two + three)\n",
    "       \n",
    "        return desiredSum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=orange> Creating all possible features in `19 by 19` window size </font> \n",
    "#  <font color=red>Feature Class </font> - A helper class for creating `Haar Feature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Feature:\n",
    "    # constructor\n",
    "    def __init__(self, image_shape):\n",
    "        \n",
    "        self.height, self.width = image_shape\n",
    "        self.f = None  # Feature list\n",
    "        self.f_values = None # Features' values for all images\n",
    "\n",
    "    def creating_all_features(self):\n",
    "\n",
    "        '''\n",
    "          Create 5 types of Haar Features for all sizes, shapes and positions in a fixed window\n",
    "        '''\n",
    "        height = self.height\n",
    "        width  = self.width\n",
    "\n",
    "        # List of tuple where 1st element means List of black rectangles and 2nd element means List of white rectangles\n",
    "        features = []\n",
    "\n",
    "        for w in range(1, width+1):      # All possible width \n",
    "            for h in range(1, height+1): # All possible height\n",
    "\n",
    "                i = 0\n",
    "                while i + w < width:\n",
    "                    j = 0\n",
    "                    while j + h < height:\n",
    "\n",
    "                        fixed   = Rectangle(i, j, w, h)\n",
    "                        right_1 = Rectangle(i+1*w, j, w, h)\n",
    "                        right_2 = Rectangle(i+2*w, j, w, h)\n",
    "\n",
    "                        bottom_1_right_1 = Rectangle(i+1*w, j+1*h, w, h)\n",
    "\n",
    "                        bottom_1 = Rectangle(i, j+1*h, w, h)\n",
    "                        bottom_2 = Rectangle(i, j+2*h, w, h)\n",
    "\n",
    "                        '''\n",
    "                           2 Rectangle Haar Features\n",
    "                        '''\n",
    "                        # Horizontal  -->  fixed (white) | right_1 (black)\n",
    "                        if i + 2 * w < width: \n",
    "                            features.append(([right_1], [fixed]))\n",
    "\n",
    "                        # Vertical -->  fixed(black)\n",
    "                                    #  ------------\n",
    "                                    #   bottom_1(white)      \n",
    "                        if j + 2 * h < height: \n",
    "                            features.append(([fixed], [bottom_1]))\n",
    "\n",
    "\n",
    "\n",
    "                        '''\n",
    "                           3 Rectangle Haar Features\n",
    "                        '''\n",
    "                        # Horizontal -->  fixed (white) | right_1 (black) | right_2 (white)\n",
    "                        if i + 3 * w < width: \n",
    "                            features.append(([right_1], [right_2, fixed]))\n",
    "\n",
    "                        # Vertical -->  fixed(white)\n",
    "                                    #  ------------\n",
    "                                    #   bottom_1(black)\n",
    "                                    #  ------------\n",
    "                                    #   bottom_2(white)\n",
    "                        if j + 3 * h < height:\n",
    "                            features.append(([bottom_1], [bottom_2, fixed]))\n",
    "\n",
    "\n",
    "                        '''\n",
    "                           4 Rectangle Haar Features\n",
    "                        '''\n",
    "\n",
    "                        if i + 2 * w < width and j + 2 * h < height:\n",
    "                            features.append(([right_1, bottom_1], [fixed, bottom_1_right_1]))\n",
    "\n",
    "                        j += 1\n",
    "                    i += 1\n",
    "\n",
    "        features = np.array(features)\n",
    "        self.f = features\n",
    "        return features\n",
    "        \n",
    "    def features_value(self, train_ds_integral):\n",
    "        '''\n",
    "          Save features' value across all training images\n",
    "        '''\n",
    "            \n",
    "        X = np.zeros((len(self.f), len(train_ds_integral))) \n",
    "        y = np.array(list(map(lambda data: data[1], train_ds_integral)))\n",
    "        \n",
    "        feature_idx = 0\n",
    "        \n",
    "        for black_regions, white_regions in self.f:\n",
    "            for k in range(len(train_ds_integral)):\n",
    "                \n",
    "                integral_img = train_ds_integral[k][0]\n",
    "                black_value = 0\n",
    "                white_value = 0\n",
    "                \n",
    "                for br in black_regions:\n",
    "                    black_value += br.compute_sum(integral_img)\n",
    "                for wr in white_regions:\n",
    "                    white_value += wr.compute_sum(integral_img)\n",
    "                    \n",
    "                X[feature_idx][k] = (black_value - white_value)\n",
    "                \n",
    "            feature_idx += 1\n",
    "            \n",
    "        self.f_values = (X,y)    \n",
    "        return X, y\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving integral images of the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_integral  = []\n",
    "\n",
    "for x in range(len(train_ds)):\n",
    "    integral_img = calcIntegral(train_ds[x][0])\n",
    "    label        = train_ds[x][1]\n",
    "    train_ds_integral.append((integral_img,label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6977"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_ds_integral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train_integral_ds.pkl\", 'wb') as f:\n",
    "    pickle.dump(train_ds_integral,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the helper class & time statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3631439208984375\n"
     ]
    }
   ],
   "source": [
    "# creating all features for a certain window shape\n",
    "s = time.time()\n",
    "\n",
    "f = Feature(train_ds[0][0].shape)\n",
    "features = f.creating_all_features()\n",
    "\n",
    "e = time.time()\n",
    "print(e-s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51705"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51705"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f.f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(features == f.f).all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1566.442535161972\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "X1, y1 = f.features_value(train_ds_integral)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the features value of training data in pickle file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_features = len(X1)\n",
    "X_first_half   = X1[:total_features//2,]\n",
    "X_second_half  = X1[ total_features//2:,]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_value_1.pkl\", 'wb') as f:\n",
    "    pickle.dump(X_first_half,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_value_2.pkl\", 'wb') as f:\n",
    "    pickle.dump(X_second_half,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_value_1.pkl\", 'rb') as f:\n",
    "    a = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"features_value_2.pkl\", 'rb') as f:\n",
    "    b = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X3 = np.concatenate((a,b), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X1==X3).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"y.pkl\", 'wb') as f:\n",
    "    pickle.dump(y1,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"y.pkl\", 'rb') as f:\n",
    "    yy = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(y1==yy).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_features.pkl\", 'wb') as file:\n",
    "    pickle.dump(features,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_features.pkl\", 'rb') as file:\n",
    "    ffff = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weak Classifier Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class wc:\n",
    "    # constructor\n",
    "    def __init__(self, black, white, threshold, polarity):\n",
    "        self.black = black\n",
    "        self.white = white\n",
    "        self.threshold = threshold\n",
    "        self.polarity = polarity\n",
    "    \n",
    "    def classify(self, integral_img):\n",
    "       \n",
    "        black_value = 0\n",
    "        white_value = 0\n",
    "                \n",
    "        for br in black:\n",
    "            black_value += br.compute_sum(integral_img)\n",
    "        for wr in white_regions:\n",
    "            white_value += wr.compute_sum(integral_img)\n",
    "\n",
    "        value = (black_value - white_value)\n",
    "                \n",
    "        if self.polarity*value < self.polarity*self.threshold:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center><font color=Blue> Viola-Jones Class --> Model </font> </center>\n",
    "\n",
    "#### In a 24 by 24 window there will be 160k + Haar Features if we consider all types of Haar Features. The model will be trained on some face and no-face images. In this training the model will learn some weak classifiers. \n",
    "\n",
    "#### Each weak classifier is based on a Haar Feature and has a weight associted with it. \n",
    "\n",
    "#### <font color=red>So, the model will have 2 properties mainly : `A list of weak classifiers` and `a list of their weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from feature import Feature\n",
    "from rectangleArea import Rectangle\n",
    "from weakClassifier import wc\n",
    "from integral import calcIntegral\n",
    "\n",
    "class VJ:\n",
    "    # constructor\n",
    "    def __init__(self, total_wc=100):\n",
    "        \n",
    "        self.total_wc           = total_wc\n",
    "        self.classifiers        = []\n",
    "        self.classifiersWeights = []\n",
    "    \n",
    "    def train(self, train_ds):\n",
    "        \n",
    "        face_count = 0\n",
    "        nonface_count = 0\n",
    "        image_count = len(train_ds)\n",
    "        \n",
    "        # face and nonface image count\n",
    "        for x in range(image_count):\n",
    "            label = train_ds[x][1]\n",
    "            if label==1:  # Face\n",
    "                face_count = face_count + 1\n",
    "            else:\n",
    "                nonface_count = nonface_count + 1\n",
    "        \n",
    "        # loading integral images of train_ds\n",
    "        with open(\"train_integral_ds.pkl\", 'rb') as f:\n",
    "            train_ds_integral = pickle.load(f)\n",
    "            print(\"Integral images are loaded from pickle file for training the model\")\n",
    "        \n",
    "        \n",
    "        w = np.zeros(image_count)  # sample_Weight\n",
    "        \n",
    "        for x in range(image_count):\n",
    "            # Initial weight of every image (sample weight)\n",
    "            if label == 1:  # Face\n",
    "                w[x] = 1.0 / (2*face_count)\n",
    "            else:\n",
    "                w[x] = 1.0 / (2*nonface_count)\n",
    "                \n",
    "        f = Feature(train_ds[0][0].shape)\n",
    "        features = f.creating_all_features()\n",
    "                \n",
    "        # load features value (X) and classification (y) from pickle file\n",
    "        # saves a lot of time while tuning in training phase\n",
    "        with open(\"features_value_1.pkl\", 'rb') as f:\n",
    "            a = pickle.load(f)\n",
    "        with open(\"features_value_2.pkl\", 'rb') as f:\n",
    "            b = pickle.load(f)\n",
    "        X = np.concatenate((a,b), axis=0) \n",
    "        with open(\"y.pkl\", 'rb') as f:\n",
    "            y = pickle.load(f)\n",
    "            \n",
    "        \n",
    "        for wc_i in range(self.total_wc):\n",
    "            \n",
    "            w = w / np.linalg.norm(w)\n",
    "            \n",
    "            trainedWeakClassifier = self.weakClassifier_training(X, y, features, w, face_count,nonface_count)\n",
    "            \n",
    "            bc = None\n",
    "            bacc = None\n",
    "            be = float('inf')\n",
    "            \n",
    "            for twc in trainedWeakClassifier:\n",
    "                e = 0\n",
    "                acc = []\n",
    "                \n",
    "                for integral_image, w in zip(train_ds_integral, w):\n",
    "                    \n",
    "                    predicted_label = twc.classify(integral_image[0])\n",
    "                    \n",
    "                    true_label = integral_image[1]\n",
    "                    \n",
    "                    acc.append(abs(predicted_label-true_label))\n",
    "                    \n",
    "                    e += w * abs(predicted_label-true_label)\n",
    "                    \n",
    "                e = e / len(image_count)\n",
    "                \n",
    "                if e < be:\n",
    "                    bc = twc\n",
    "                    be = e\n",
    "                    bacc = acc\n",
    "            \n",
    "            beta = be / (1.0 - be)\n",
    "            \n",
    "            for i in range(len(bacc)):\n",
    "                w[i] = w[i] * (beta ** (1 - bacc[i]))\n",
    "                \n",
    "            alpha = math.log(1.0/beta)\n",
    "            self.classifiersWeights.append(alpha)\n",
    "            self.classifiers.append(bc)\n",
    "            \n",
    "        \n",
    "    def weakClassifier_training(self, X, y, features, weights, face_count,nonface_count):\n",
    "    \n",
    "        total_pos_weights, total_neg_weights = 0, 0\n",
    "\n",
    "        for w, label in zip(weights, y):\n",
    "\n",
    "            if label == 1:\n",
    "                total_pos_weights = total_pos_weights + w\n",
    "            else:\n",
    "                total_neg_weights = total_neg_weights + w\n",
    "\n",
    "        c = []\n",
    "\n",
    "        for index, feature in enumerate(X):\n",
    "\n",
    "            # sort according to feature value\n",
    "            sortedList = sorted(zip(weights,feature, y), key=lambda x: x[1])\n",
    "\n",
    "            pos_img_seen = 0\n",
    "            neg_img_seen = 0\n",
    "            pos_img_weights = 0\n",
    "            neg_img_weights = 0\n",
    "\n",
    "            min_e = float('inf')\n",
    "            bf = None\n",
    "            bt = None\n",
    "            bp = None\n",
    "\n",
    "            for w, f, label in sortedList:\n",
    "\n",
    "                error = min(neg_img_weights + total_pos_weights - pos_img_weights, pos_img_weights + total_neg_weights - neg_img_weights)\n",
    "\n",
    "                if error < min_e:\n",
    "                    min_e = error\n",
    "                    bf = features[index]\n",
    "                    bt = f\n",
    "                    if pos_img_seen > neg_img_seen:\n",
    "                        bt = 1\n",
    "                    else:\n",
    "                        bt = -1\n",
    "\n",
    "                if label == 1:\n",
    "                    pos_img_seen += 1\n",
    "                    pos_img_weights += w\n",
    "                else:\n",
    "                    neg_img_seen += 1\n",
    "                    neg_img_weights += w\n",
    "\n",
    "            black_region = bf[0]\n",
    "            white_region = bf[1]\n",
    "\n",
    "            weak_c = wc(black_region,white_region,bt,bp)\n",
    "\n",
    "            c.append(weak_c)\n",
    "\n",
    "        return c\n",
    "    \n",
    "    def classify(self, image):\n",
    "        total = 0\n",
    "        integral_image = calcIntegral(image)\n",
    "        \n",
    "        for c_w, cl in zip(self.classifiersWeights, self.classifiers):\n",
    "            total += c_w * cl.classify(integral_image)\n",
    "            \n",
    "        if total >= 0.5 * sum(self.classifiersWeights):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    def saveModel(self, filename):\n",
    "        with open(filename+\".pkl\", 'wb') as f:\n",
    "            pickle.dump(self, f)\n",
    "\n",
    "    @staticmethod\n",
    "    def loadModel(filename):\n",
    "        with open(filename+\".pkl\", 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
